---
title: "City Pop vs US Pop"
author: 
date: 
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    orientation: columns 
---

```{r setup, include=FALSE}
library(tidyverse)
library(spotifyr)
library(ggplot2)
library(flexdashboard)
library(plotly)
library(compmus)

```

```{r load data, include=FALSE}
cityPopPlaylist <- get_playlist_audio_features("", "7LNMKu5boirXk30CB0mh7W")
popPlaylist <- get_playlist_audio_features("", "64h8THGlWTBkbE7sqhRV4V")
```

```{r bind data, include=FALSE}
comparison <- 
    bind_rows(
      cityPopPlaylist |> mutate(category = "City Pop"),
      popPlaylist |> mutate(category = "US Pop")
    )
```


Histograms of keys *NEW*
=======================================

```{r}
energy_hist <- comparison |> 
 ggplot(
    aes(
      x = key, fill = category
      )
    ) + 
  geom_histogram(
    binwidth = 0.1, 
    position = position_dodge(0.3)
    ) + 
  labs(
    y = "Amount of Songs", 
    x = "Key", 
    title = "Key distribution between City Pop and Pop", 
    citation = "Data: Personal Playlists")

ggplotly(energy_hist)
```


Chordograms of Archetypes *NEW* {.storyboard}
=======================================

```{r, include=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```


### Mayonaka no Door/Stay With Me     City Pop
```{r}
Stay <-
  get_tidy_audio_analysis("2BHj31ufdEqVK5CkYDp9mA") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
Stay |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### 4:00A.M.     City Pop

```{r}
four_am <-
  get_tidy_audio_analysis("0zoGVO4bQXG8U6ChKwNgeg") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
four_am |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


### Remember Summer Days     City Pop

```{r}
remember <-
  get_tidy_audio_analysis("1qUo7d5lAOclNVbTUY0A2R") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
remember |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### I Wanna Dance With Somebody (Who Loves Me)     Pop

```{r}
wanna_dance <-
  get_tidy_audio_analysis("2tUBqZG2AbRi7Q0BIrVrEj") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
wanna_dance |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


### Material Girl     Pop

```{r}
material_girl <-
  get_tidy_audio_analysis("7bkyXSi4GtVfD7itZRUR3e") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
material_girl |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


### Thriller     Pop

```{r}
thriller <-
  get_tidy_audio_analysis("2LlQb7Uoj1kKyGhlkBf9aC") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
thriller |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```


Standard Deviation Plot *NEW*
==============================

```{r}
city_Pop <-
  get_playlist_audio_features(
    "Computational Musicology Japanese",
    "7LNMKu5boirXk30CB0mh7W"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
us_Pop <-
  get_playlist_audio_features(
    "Computational Musicology American",
    "64h8THGlWTBkbE7sqhRV4V"
  ) |>
  slice(1:30) |>
  add_audio_analysis()
pop <-
  city_Pop |>
  mutate(genre = "City Pop") |>
  bind_rows(us_Pop |> mutate(genre = "U.S. Pop"))
```

```{r}
pop |>
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = loudness,
      y = loudness_section_sd,
      colour = genre,
      alpha = tempo
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 10) +
  labs(
    x = "Mean Loudness",
    y = "SD Loudness",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Tempo"
  )
```


City Pop and Pop, the same despite being a world apart from one another? 
=======================================


### The corpus:  

 -PLEASE DO NOT SHOW THIS PORTFOLIO IN CLASS-   
    
 
I am comparing two playlists consisting of three artists, one Japanese group and one US playlist. The Japanese group consist of the artists Taeko Onuki, Miki Matsubara and Anri. The US counterparts are the artists Michael Jackson, Whitney Houston and Madonna. I chose these corpora because I want to explore whether there are distinct differences between the genre of (city) pop as it was in Japan in the 80's vs the pop that was popular in the western world in the same decade. Japanese city pop was influenced by western music, so I expect there to be many similarities in use of sound, instruments and type of rhythms. However, an aspect I am particularly interested whether there is a difference is the prevalence of bass, and rhythms. It is also interesting to see whether there are differences in other aspects like "supplementary" sounds. However, I am unsure to what extent they are different.  
    
As I have chosen three artists to represent their own (variety) of genres, there might be nuances and representations I am missing. Taeko Onuki, Miki Matsubara and Anri were chosen due to their popularity on Spotify (the amount of general listeners as well as listens to their tracks). I also have to mention that there were personal selections. The same method was done in choosing the western counterparts. However, the genre(s) is (are) very broad, despite its popularity, and some varieties might have been overlooked. However, their popularity is a strength. 
  

***

Typical, and popular, tracks from the Japanese playlist are:

  - "Mayonaka no Door / Stay With Me" - Miki Matsubara
  - "4:00A.M." - Taeko Onuki
  - "Remember Summer Days" - Anri  

These songs are typical in the sense that there are prominent use of basslines and clear rhythms, and have many "layers" to them. 

The western counterparts have typical tracks like: 

  - "Billie Jean" - Michael Jackson
  - "I Wanna Dance with Somebody (Who Loves Me)"
  - "Material Girl" - Madonna  
  
These last three tracks especially has the typical and distinct features of pop of the 80's, namely the sharp drums and the heavily synthesized piano sounds and, what I think, an almost like a "dreamy" sound to them. 
  



Tempo, danceability and energy {.storyboard}
===========================================


### Distribution of energy between City Pop and US Pop  

```{r interactive plot}
energy_hist <- comparison |> 
 ggplot(
    aes(
      x = energy, fill = category
      )
    ) + 
  geom_histogram(
    binwidth = 0.1, 
    position = position_dodge(0.3)
    ) + 
  labs(
    y = "Amount of Songs", 
    x = "Energy", 
    title = "Distribution of Energy between City Pop and Pop", 
    citation = "Data: Personal Playlists")

ggplotly(energy_hist)
```

 Here are plots to give insight in the general tempos effect on danceability (and energy) in the groups City Pop and US Pop. In the first histogram plot, one can see that the distribution of energy is more even for pop than for city pop. It says that it counted 15 of the data in my playlist for City Pop to have an energy of a little over 0.6.  



### Energy, danceability and tempo 


```{r interactive }
int_danceability <- comparison |>
  ggplot(
    aes(
      x = energy, 
      y = danceability, 
      color = category, 
      size = tempo
      )
    ) + 
    geom_point(
      alpha = 0.5
      ) + 
    geom_jitter() +
    geom_smooth() +
    facet_wrap(~category) +
    labs(title = "The effect of energy on danceability for City Pop and US Pop")

ggplotly(int_danceability)
```

Here is a plot of the effect of energy on danceability, with size of the plots as well as the band around the line indicating the tempo of the songs. One can see that there is more of a linear trend with US Pop, indicating that up until around energy of 0.5 there seems to be a correlation between energy and danceability. Tempo, however, do seem to have no pattern at first glance. Whereas for the City Pop playlist, there seem to be a slight curve in the beginning of the graph, but overall there is a very even trend of the effect of energy on danceability. At first glance, there also seem to be no indication that there is a trend for tempo.  


Chromagram of Billie Jean *UPDATED*
====================================


```{r}
bjean <- 
    get_tidy_audio_analysis("7J1uxwnxfQLu4APicE5Rnj") |>
    select(segments) |>
    unnest(segments) |>
    select(start, duration, pitches)

bjean |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

"Billie Jean" was listed as an outlier for the Pop group in the graph of whether energy has an effect on danceability, in the sense that Spotify notices this as a quite unenergetic song, while having an extremely high danceability. As one can see in this chromagram, the song "Billie Jean" has several areas where the magnitude is over 0.75. A couple of patterns that arise are the use of the D and C#/Db at before 100 and 200 seconds. They form an almost pyramid shape. However, depsite this, one can see that it is a very energetic song, by the use of the chromas - despite being a very slow and "unenergetic" song. 


Danceability, valence and mode {.storyboard}
==========================================


### Other differences 

The previous plots made me think that there is more to the differences between city pop and US pop. Danceability for city pop seemed overall lower than for US pop, indicating that there are more differences in their features than I previously thought. Personally, when listening to city pop, I often get a feeling of a certain melancholy, even while you may want to dance. Therefore, I decided to explore these features.  


### Distribution of valence

```{r}
comparison |> ggplot(aes(x = valence, fill = category)) + geom_histogram(binwidth = 0.1, position = position_dodge()) + labs(title = "Distribution of Valence in City Pop and US Pop") 
```
 


### Danceability, valence and mode

Starting with valence, I wanted to see whether there were differences in distributions for the valence in the two groups/playlists. The histogram below does seem to indicate that there is more songs that are considered very happy, but this could be attributed to the fact that the city pop playlist has more songs than in the US Pop playlist. Therefore, I made another scatterplot to explore further.  


```{r}
plot_mode <- comparison |>
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
    ) |>
  ggplot(
    aes(
      x = danceability, 
      y = valence, 
      color = category,
      shape = mode)
    ) + 
    geom_point() + 
    geom_jitter(
      alpha = 0.1
      ) + 
    facet_wrap(
      ~category
      ) +
    labs(
      title = "The effect of danceability on valence, with shape indicating major or minor", 
      x = "Danceability", 
      y = "Valence"
    )

ggplotly(plot_mode)
```

*** 

The graph below show the danceability's effect on valence, with the shape indicating the mode of the song, i.e., whether it is major or minor. Overall, there seems to be a trend of danceability having an effect on valency in the US group, as there is more of a cluster where the danceability is high and having a high valence. A similar trend seems to be the case in the Japanese group as well. However, whereas many of the songs in the US group has a danceability over 0.8, with high valance, this is not really the case for the other group. Many of the latter's songs are under 0.8 in danceability, but have a high valence nonetheless. For both groups, there seem to be no striking pattern at first glance for the mode.  


Conclusions/Summary
==================================

### Differences in City Pop vs US Pop 

So far we can see that the differences between US Pop and City Pop, based on the corpus I am using, is that energy definitely seem to have an effect on danceability in US pop, up until a certain level. However, there are many outliers that can skew this, which will be identified shortly. Furthermore, it does not seem that tempo has a definite pattern on either energy or danceability. 

Furthermore, another difference is that danceability seem to have more of an effect on the positive valence in both genres. However, one can see that there are more songs in US pop that are more danceable and that are happier than City Pop.  

This makes sense, given the fact that according to the histogram, none of the city pop songs go above a certain threshold of valence, in comparison to US pop. This could indicate that city pop is generally less "happy".  

But one outlier I want to talk about in particular is the one track, in the energy, danceability and tempo plot, where the energy is quite low in comparison to other tracks, but the danceability is one of the highest in the group. While I am not sure how to point this out in the plot, I have managed to identify it as the track "Billie Jean" by Michael Jackson. A seperate chromagram has been made in order to account for this. 

### Homework Conclusions 

I have managed to do most of the homework for tomorrow! However, I am not entirely sure how to identify the outliers in the plot itself, and will ask for help next seminar. Furthermore, I am not entirely sure what is meant by "annotate several key moments". This also I hope I can understand next seminar.

As a side-note, I am still unsure whether the variables I am using are effective and make sense in what I try to understand. Does it make sense to use energy on danceability? As well, does it make sense to look at danceabilities effect on valence? If I could get some feedback on this, that would be awesome. Thank you! 
